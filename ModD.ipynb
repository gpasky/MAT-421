{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaaGgjvu40v8FigO0Ri+3E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gpasky/MAT-421/blob/main/ModD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gabriel Pascual"
      ],
      "metadata": {
        "id": "ijhWSG2PWLx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2.1 Linear Spaces**\n",
        "\n",
        "A linear subspace is the result of a linear combination that multiplies each vector from a subset by a constant and sums up the end results.\n",
        "\n",
        "Definition of Linear subspace:\n",
        "$V$ is a subset $U ⊆ V$\n",
        "\n",
        "$\\forall$ $u_1,u_2 \\in U,$ $and$ $αu_1 \\in U$\n",
        "\n",
        "A linear subspace always contains 0"
      ],
      "metadata": {
        "id": "aW17Va8QWN9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2.2\n",
        "\n",
        "Span: The set of all linear combinations of the $w_j$'s\n",
        "\n",
        "$span(w_1,...,w_m)$ = ${∑_{j=1}^{m}} a_jw-j: a_1,...a_m\\in\\mathbb{R}$\n",
        "\n",
        "*   A list of vectors could span a linear subspace\n",
        "\n",
        "A span is a linear subspace:\n",
        "\n",
        "Let $W = span(w_1,...,w_m)$ = **linear subspace**\n",
        "\n",
        "The conditions $u_1,u_2 \\in U,$ $and$ $αu_1 \\in U$ are satisfied for a linear subspace since\n",
        "\n",
        "$au_1+u_2 = ∑_{j=1}^{m}(aβ_1,j+β_2,j)w_j$ given i = 1,2.\n",
        "\n",
        "This represents a linear combination from combining both conditions\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Cfzijg6hN34e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2.4\n",
        "\n",
        "Column space: Given a matrix of $n$ x $m$ with columns $a_1...,a_m\\in \\mathbb{R^n}$, the linear combination of these vectors is $col(A) = span(a_1,...,a_m)$."
      ],
      "metadata": {
        "id": "xxBXZ1yvnMLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2.1.2\n",
        "\n",
        "Linear Independence and Dimension:\n",
        "\n",
        "*   Linear independence occurs if none of the vectors $u_1...,u_m$ can be a linear combination of the others\n",
        "\n",
        "$∀i, u_i ∉ span({u_j: j\\not_= i})$\n",
        "\n",
        "*   Linear dependence occurs if $\\sum_{j=1}^{m}a_ju_j=0$ given that $∃a_j$ not all zero, whereas independence occurs if the condition implies $a_j=0, ∀j$.\n",
        "\n",
        "Ex: v = [1,2,0], w = [0,0,3], u = [2,0,0].\n",
        "Then w is linearly independent from v and u since its third element is greater than 0, v and u are linearly independent since v contains a value greater than zero on its second element.\n",
        "\n",
        "*   Dimension Theorem: When given U to be a linear subspace of V, the basis contains the same number of elements (dimension or dim(U))"
      ],
      "metadata": {
        "id": "WpEMgs0Zqqwl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2.2 Orthogonality**\n",
        "\n",
        "1.2.2.1\n",
        "\n",
        "Orthonormal Bases: Vectors ${u_1,...,u_m}$ are orthonormal if $u_i$'s are pairwise orthogonal(perpendicular) and each has a norm equal to 1:\n",
        "\n",
        "*   $<u_i,u_j> = u_i * u_j=0$\n",
        "*   $\\|u_i\\|=1$\n",
        "\n",
        "An example can be made using vectors v = [0,3,8] and w = [-10,-8,3]."
      ],
      "metadata": {
        "id": "-m7O449oyjEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "from numpy import arccos, dot\n",
        "\n",
        "v = np.array([[0,3,8]])\n",
        "w = np.array([[-10,-8,3]])\n",
        "theta = \\\n",
        "    arccos(dot(v,w.T)/(norm(v)*norm(w)))\n",
        "print(theta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaDw8yG4HnXx",
        "outputId": "daad6f0e-072d-4812-8ee6-adab5b9ab59c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.57079633]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get a result of $1.57079633 ≈ π / 2$ radians which means that the vectors are orthogonal."
      ],
      "metadata": {
        "id": "b6iKKC0rIUeX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2.2.2\n",
        "\n",
        "Best Approximation Theorem:\n",
        "Given a linear subspace $S ⊆ V$ and vector v not in that subspace, we find v* in S closest to v$.\n",
        "\n",
        "Ex: $S=span(u_1)$ where $\\| u_1\\| = 1$. Solving for v* we see that v-v* is orthogonal to $u_1$.\n",
        "\n",
        "Let $v^*=a^*u_1$\n",
        "\n",
        "*   $0=<u_1,v-v^*>$\n",
        "*   $0=<u_1,v>$ - $a^*$\n",
        "*   $a^*=<u_1,v>$\n",
        "\n",
        "Thus,  $v^*=<u_1,v>u_1$"
      ],
      "metadata": {
        "id": "SQcGqlupLfzc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2.4 Eigenvalues and Eigenvectors**\n",
        "\n",
        "$Ax=λx$ where $λ$ is an eigenvalue of matrix A if it holds true with the matrix A. The x vector is an eigenvector associated to $λ$. Eigenvectors transform Ax while the eigenvalues are the scale factors for this transformation.\n",
        "\n",
        "An example can be made to find both eigenvalues and eigenvectors of the matrix $A=\\begin{bmatrix}0&2\\\\2&3\\end{bmatrix}$\n"
      ],
      "metadata": {
        "id": "hyFitwhxSQR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "A = np.array([[0,3],[3,4]])\n",
        "\n",
        "eigenvalue,eigenvector = np.linalg.eig(A)\n",
        "\n",
        "print(\"Eigenvalue:\",eigenvalue,\"\\nEigenvector:\",eigenvector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9RwgJ8SViCR",
        "outputId": "6bc06965-3451-488e-990c-b7eecd10af9f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eigenvalue: [-1.60555128  5.60555128] \n",
            "Eigenvector: [[-0.8816746  -0.47185793]\n",
            " [ 0.47185793 -0.8816746 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uKjC_5hSRecV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Power Method can also be used to find the largest eigenvalue with its eigenvector. This iterative method takes the n x n matrix A with $λ_n$ eigenvalues and $v_1,...v_n$ eigenvectors with the contraint $|λ_1| > |λ_2|$.\n",
        "\n",
        "$Ax_{k-1}=λ_1[v_1+\\frac{c_2}{c_1}\\frac{\\lambda_{2}^{k}}{\\lambda_{1}^{k}}v_2+...+v_1+\\frac{c_n}{c_n}\\frac{\\lambda_{n}^{k}}{\\lambda_{n}^{k}}v_n$\n",
        "\n",
        "\n",
        "\n",
        "*   For a large k, we eventually end up with the largest eigenvalue\n",
        "\n",
        "*   By factoring out the largest element in the vector of each iteration, we normalize to get the vector equal to 1\n",
        "\n",
        "An example can be made to show this iterative process:"
      ],
      "metadata": {
        "id": "TJ3tmwLqYbVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def normalize(x):\n",
        "  fac = abs(x).max()\n",
        "  x_n = x / x.max()\n",
        "  return fac, x_n\n",
        "\n",
        "x = np.array([1,1])\n",
        "a = np.array([[0,3],[3,4]])\n",
        "\n",
        "for i in range(8):\n",
        "  x = np.dot(a,x)\n",
        "  lambda_1, x = normalize(x)\n",
        "\n",
        "print(\"Eigenvalue:\",lambda_1,\"\\nEigenvector:\",x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2ex2MEZZ-15",
        "outputId": "76f1e529-09aa-4976-dc3f-820fb60340a9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eigenvalue: 5.60536649529986 \n",
            "Eigenvector: [0.5352014 1.       ]\n"
          ]
        }
      ]
    }
  ]
}